{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import hashlib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "def read():\n",
    "    dfa = pd.read_csv(\"../data/input/merged_profiles.csv\")\n",
    "    dfb = pd.read_csv(\"../data/input/personnel.csv\")\n",
    "    return dfa, dfb\n",
    "\n",
    "def read_model(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "dfa, dfb = read()\n",
    "model = read_model('../../ts-train-model/data/output/trained_lr_model.pkl')\n",
    "\n",
    "dfa[\"source\"] = \"wci\"\n",
    "dfa[\"agency\"] = \"n/a\"\n",
    "\n",
    "dfb[\"source\"] = \"llead\"\n",
    "dfb[\"officer_role\"] =\"n/a\"\n",
    "dfb[\"officer_context\"] = \"n/a\"\n",
    "dfb = dfb[dfb.agency.str.contains(\"orleans-pd|orleans-so\")]\n",
    "\n",
    "def create_hash_uid(row):\n",
    "    unique_string = f\"{row['first_name1']}|{row['last_name1']}|{row['first_name2']}|{row['last_name2']}|{row['source1']}|{row['source2']}\"\n",
    "    return hashlib.md5(unique_string.encode()).hexdigest()\n",
    "\n",
    "dfa = dfa.rename(columns={\"person_uid\":  \"wcoi_uid\"})\n",
    "dfb = dfb.rename(columns={\"uid\": \"llead_uid\"})\n",
    "\n",
    "df = pd.concat([dfa, dfb])\n",
    "\n",
    "df.loc[:, \"first_name\"] = df.first_name.str.lower().str.strip()\n",
    "df.loc[:, \"last_name\"] = df.last_name.str.lower().str.strip()\n",
    "\n",
    "df.loc[:, \"fc\"] = df.first_name.fillna(\"\").map(lambda x: x[:1])\n",
    "df.loc[:, \"lc\"] = df.last_name.fillna(\"\").map(lambda x: x[:1])\n",
    "\n",
    "df = df[[\"first_name\", \"last_name\", \"fc\", \"lc\", \"source\", \"wcoi_uid\", \"llead_uid\", \"agency\"]]\n",
    "\n",
    "print(f\"DF SHAPE BEFORE {df.shape}\")\n",
    "df = df.drop_duplicates(subset=[\"wcoi_uid\", \"llead_uid\"])\n",
    "print(f\"DF SHAPE AFTER {df.shape}\")\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "df.loc[:, \"full_name\"] = df.first_name.str.cat(df.last_name, sep=\" \")\n",
    "df = df[~((df.full_name.fillna(\"\") == \"\"))]\n",
    "\n",
    "full_names = df.first_name.str.cat(df.last_name, sep=\" \")\n",
    "\n",
    "def calculate_similarity(row1, row2):\n",
    "    features = [\n",
    "        abs(len(row1['first_name']) - len(row2['first_name'])),\n",
    "        abs(len(row1['last_name']) - len(row2['last_name'])),\n",
    "        int(row1['first_name'][0] == row2['first_name'][0]),\n",
    "        int(row1['last_name'][0] == row2['last_name'][0]),\n",
    "        len(set(row1['first_name']) & set(row2['first_name'])) / max(len(row1['first_name']), len(row2['first_name'])),\n",
    "        len(set(row1['last_name']) & set(row2['last_name'])) / max(len(row1['last_name']), len(row2['last_name']))\n",
    "    ]\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_features = scaler.fit_transform([features])\n",
    "    similarity_score = model.predict_proba(scaled_features)[0][1]  # Probability of positive class\n",
    "    \n",
    "    return similarity_score\n",
    "\n",
    "def custom_matcher(df):\n",
    "    results = []\n",
    "    \n",
    "    wci_df = df[df['source'] == 'wci']\n",
    "    llead_df = df[df['source'] == 'llead']\n",
    "    \n",
    "    for _, wci_row in wci_df.iterrows():\n",
    "        best_match = None\n",
    "        best_score = -1\n",
    "        \n",
    "        for _, llead_row in llead_df.iterrows():\n",
    "            if wci_row['fc'] == llead_row['fc'] and wci_row['lc'] == llead_row['lc']:\n",
    "                sim_score = calculate_similarity(wci_row, llead_row)\n",
    "                \n",
    "                if sim_score > best_score:\n",
    "                    best_score = sim_score\n",
    "                    best_match = llead_row\n",
    "        \n",
    "        if best_match is not None:\n",
    "            results.append({\n",
    "                'sim_score': best_score,\n",
    "                'first_name1': wci_row['first_name'],\n",
    "                'last_name1': wci_row['last_name'],\n",
    "                'fc1': wci_row['fc'],\n",
    "                'source1': wci_row['source'],\n",
    "                'agency1': wci_row['agency'],\n",
    "                'wcoi_uid1': wci_row['wcoi_uid'],\n",
    "                'llead_uid1': wci_row['llead_uid'],\n",
    "                'first_name2': best_match['first_name'],\n",
    "                'last_name2': best_match['last_name'],\n",
    "                'fc2': best_match['fc'],\n",
    "                'source2': best_match['source'],\n",
    "                'agency2': best_match['agency'],\n",
    "                'wcoi_uid2': best_match['wcoi_uid'],\n",
    "                'llead_uid2': best_match['llead_uid']\n",
    "            })\n",
    "    \n",
    "    result_df = pd.DataFrame(results)\n",
    "    result_df = result_df.sort_values('sim_score', ascending=False)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "df = custom_matcher(df)\n",
    "df['person_uid'] = df.apply(create_hash_uid, axis=1)\n",
    "\n",
    "df.to_csv(\"../data/output/merged_officer_profiles_with_best_matches.csv\", index=False)\n",
    "print(f\"Final DataFrame shape: {df.shape}\")\n",
    "print(f\"Number of unique WCI entities matched: {df['wcoi_uid1'].nunique()}\")\n",
    "print(f\"Number of unique LLEAD entities matched: {df['llead_uid2'].nunique()}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
