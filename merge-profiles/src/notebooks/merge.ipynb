{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 389, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_chunk' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ayyub/Desktop/entity-resolution/wrongful-convictions-entity-res/merge-profiles/src/merge.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ayyub/Desktop/entity-resolution/wrongful-convictions-entity-res/merge-profiles/src/merge.ipynb#W0sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m chunks \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m../../feature-engineering/data/output/output.csv\u001b[39m\u001b[39m'\u001b[39m, chunksize\u001b[39m=\u001b[39mchunk_size)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ayyub/Desktop/entity-resolution/wrongful-convictions-entity-res/merge-profiles/src/merge.ipynb#W0sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m \u001b[39m# Process chunks in parallel\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/ayyub/Desktop/entity-resolution/wrongful-convictions-entity-res/merge-profiles/src/merge.ipynb#W0sZmlsZQ%3D%3D?line=108'>109</a>\u001b[0m merged_profiles, entity_to_profile_map \u001b[39m=\u001b[39m merge_profiles_parallel(pd\u001b[39m.\u001b[39;49mconcat(chunks))\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ayyub/Desktop/entity-resolution/wrongful-convictions-entity-res/merge-profiles/src/merge.ipynb#W0sZmlsZQ%3D%3D?line=110'>111</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNumber of merged profiles: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(merged_profiles)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/ayyub/Desktop/entity-resolution/wrongful-convictions-entity-res/merge-profiles/src/merge.ipynb#W0sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNumber of mapped entities: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(entity_to_profile_map)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/Users/ayyub/Desktop/entity-resolution/wrongful-convictions-entity-res/merge-profiles/src/merge.ipynb Cell 1\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ayyub/Desktop/entity-resolution/wrongful-convictions-entity-res/merge-profiles/src/merge.ipynb#W0sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m chunks \u001b[39m=\u001b[39m [df[i:i\u001b[39m+\u001b[39mchunk_size] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(df), chunk_size)]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ayyub/Desktop/entity-resolution/wrongful-convictions-entity-res/merge-profiles/src/merge.ipynb#W0sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m process_chunk_partial \u001b[39m=\u001b[39m partial(process_chunk, threshold\u001b[39m=\u001b[39mthreshold)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ayyub/Desktop/entity-resolution/wrongful-convictions-entity-res/merge-profiles/src/merge.ipynb#W0sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m results \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49mmap(process_chunk_partial, chunks)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ayyub/Desktop/entity-resolution/wrongful-convictions-entity-res/merge-profiles/src/merge.ipynb#W0sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m pool\u001b[39m.\u001b[39mclose()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ayyub/Desktop/entity-resolution/wrongful-convictions-entity-res/merge-profiles/src/merge.ipynb#W0sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m pool\u001b[39m.\u001b[39mjoin()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[39m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[39m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, mapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    769\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    656\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    356\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "import os\n",
    "\n",
    "def process_chunk(chunk, threshold=0.5):\n",
    "    local_merged_profiles = defaultdict(lambda: {\n",
    "        'entity_uids': set(),\n",
    "        'first_name': '',\n",
    "        'last_name': '',\n",
    "        'roles': set(),\n",
    "        'contexts': set()\n",
    "    })\n",
    "    local_entity_to_profile_map = {}\n",
    "\n",
    "    for _, row in chunk.iterrows():\n",
    "        entity_1_uid = row['entity_1_uid']\n",
    "        entity_2_uid = row['entity_2_uid']\n",
    "        prediction = row['prediction']\n",
    "        \n",
    "        if prediction > threshold:\n",
    "            profile_key_1 = local_entity_to_profile_map.get(entity_1_uid)\n",
    "            profile_key_2 = local_entity_to_profile_map.get(entity_2_uid)\n",
    "            \n",
    "            if profile_key_1 is None and profile_key_2 is None:\n",
    "                new_key = max(local_merged_profiles.keys(), default=-1) + 1\n",
    "                profile_key_1 = profile_key_2 = new_key\n",
    "            elif profile_key_1 is None:\n",
    "                profile_key_1 = profile_key_2\n",
    "            elif profile_key_2 is None:\n",
    "                profile_key_2 = profile_key_1\n",
    "            \n",
    "            profile = local_merged_profiles[profile_key_1]\n",
    "            other_profile = local_merged_profiles[profile_key_2]\n",
    "            \n",
    "            # Merge profiles\n",
    "            profile['entity_uids'].update(other_profile['entity_uids'])\n",
    "            profile['entity_uids'].update([entity_1_uid, entity_2_uid])\n",
    "            profile['roles'].update(other_profile['roles'])\n",
    "            profile['roles'].update([row['entity_1_role'], row['entity_2_role']])\n",
    "            profile['contexts'].update(other_profile['contexts'])\n",
    "            profile['contexts'].update([row['entity_1_context'], row['entity_2_context']])\n",
    "            \n",
    "            # Update name if necessary\n",
    "            if not profile['first_name']:\n",
    "                profile['first_name'] = row['entity_1_first_name']\n",
    "            if not profile['last_name']:\n",
    "                profile['last_name'] = row['entity_1_last_name']\n",
    "            \n",
    "            # Update local_entity_to_profile_map\n",
    "            for uid in profile['entity_uids']:\n",
    "                local_entity_to_profile_map[uid] = profile_key_1\n",
    "            \n",
    "            # Remove other profile if it was different\n",
    "            if profile_key_2 != profile_key_1:\n",
    "                del local_merged_profiles[profile_key_2]\n",
    "\n",
    "    return local_merged_profiles, local_entity_to_profile_map\n",
    "\n",
    "def merge_chunk_results(results):\n",
    "    global_merged_profiles = defaultdict(lambda: {\n",
    "        'entity_uids': set(),\n",
    "        'first_name': '',\n",
    "        'last_name': '',\n",
    "        'roles': set(),\n",
    "        'contexts': set()\n",
    "    })\n",
    "    global_entity_to_profile_map = {}\n",
    "    \n",
    "    for local_merged_profiles, local_entity_to_profile_map in results:\n",
    "        for profile_key, profile in local_merged_profiles.items():\n",
    "            global_key = len(global_merged_profiles)\n",
    "            global_profile = global_merged_profiles[global_key]\n",
    "            global_profile['entity_uids'].update(profile['entity_uids'])\n",
    "            global_profile['roles'].update(profile['roles'])\n",
    "            global_profile['contexts'].update(profile['contexts'])\n",
    "            if not global_profile['first_name']:\n",
    "                global_profile['first_name'] = profile['first_name']\n",
    "            if not global_profile['last_name']:\n",
    "                global_profile['last_name'] = profile['last_name']\n",
    "            \n",
    "            for uid in profile['entity_uids']:\n",
    "                global_entity_to_profile_map[uid] = global_key\n",
    "\n",
    "    return global_merged_profiles, global_entity_to_profile_map\n",
    "\n",
    "def merge_profiles_parallel(df, threshold=0.5, chunk_size=100000):\n",
    "    num_processes = os.cpu_count()\n",
    "    pool = mp.Pool(processes=num_processes)\n",
    "\n",
    "    chunks = [df[i:i+chunk_size] for i in range(0, len(df), chunk_size)]\n",
    "    process_chunk_partial = partial(process_chunk, threshold=threshold)\n",
    "    \n",
    "    results = pool.map(process_chunk_partial, chunks)\n",
    "    \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    return merge_chunk_results(results)\n",
    "\n",
    "\n",
    "# Read the CSV file in chunks\n",
    "chunk_size = 100000  # Adjust this based on your available memory\n",
    "chunks = pd.read_csv('../../feature-engineering/data/output/output.csv', chunksize=chunk_size)\n",
    "\n",
    "# Process chunks in parallel\n",
    "merged_profiles, entity_to_profile_map = merge_profiles_parallel(pd.concat(chunks))\n",
    "\n",
    "print(f\"Number of merged profiles: {len(merged_profiles)}\")\n",
    "print(f\"Number of mapped entities: {len(entity_to_profile_map)}\")\n",
    "\n",
    "# Create a new DataFrame for the merged profiles\n",
    "merged_df = pd.DataFrame([\n",
    "        {\n",
    "            'profile_id': key,\n",
    "            'entity_uids': ','.join(profile['entity_uids']),\n",
    "            'first_name': profile['first_name'],\n",
    "            'last_name': profile['last_name'],\n",
    "            'roles': ','.join(profile['roles']),\n",
    "            'contexts': ' '.join(profile['contexts'])\n",
    "        }\n",
    "        for key, profile in merged_profiles.items()\n",
    "    ])\n",
    "\n",
    "print(\"Merged DataFrame shape:\", merged_df.shape)\n",
    "merged_df.to_csv(\"../data/output/merged_df.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
