{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import nltk\n",
    "from itertools import combinations\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import jellyfish\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv():\n",
    "    df = pd.read_csv(\"../../blocking/data/output/blocks.csv\")\n",
    "    return df \n",
    "\n",
    "# def read_csv():\n",
    "#     df = pd.read_csv(\"../../preprocessing/data/output/clean.csv\")\n",
    "#     df = df.fillna(\"\")\n",
    "#     return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno 8] nodename nor\n",
      "[nltk_data]     servname provided, or not known>\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')  \n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "def tokenize_and_stem(context):\n",
    "    tokens = word_tokenize(context)  \n",
    "    stemmed_tokens = stem_tokens(tokens) \n",
    "    return stemmed_tokens\n",
    "\n",
    "def calculate_string_similarity(s1, s2):\n",
    "    return jellyfish.jaro_winkler_similarity(s1, s2)\n",
    "\n",
    "def calculate_context_similarity(contexts1, contexts2):\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "    embeddings1 = model.encode(contexts1, convert_to_tensor=True)\n",
    "    embeddings2 = model.encode(contexts2, convert_to_tensor=True)\n",
    "    \n",
    "    embeddings1_np = embeddings1.cpu().numpy()\n",
    "    embeddings2_np = embeddings2.cpu().numpy()\n",
    "    \n",
    "    cosine_similarities = np.diag(cosine_similarity(embeddings1_np, embeddings2_np)).tolist()\n",
    "    \n",
    "    return cosine_similarities\n",
    "\n",
    "def generate_pairwise_comparisons(df):\n",
    "    df = df.fillna(\"\")\n",
    "    comparison_data = []\n",
    "\n",
    "    # Flatten the list of all blocking keys to find unique keys across the dataset\n",
    "    all_keys = set([key for sublist in df['blocking_keys'] for key in sublist])\n",
    "    \n",
    "    for key in all_keys:\n",
    "        # Find all records that have this blocking key\n",
    "        filtered_df = df[df['blocking_keys'].apply(lambda x: key in x)]\n",
    "        unique_entities = filtered_df['person_uid'].unique()\n",
    "\n",
    "        # Generate all combinations of unique entities within this filtered group\n",
    "        for entity_1, entity_2 in combinations(unique_entities, 2):\n",
    "            entity_1_row = filtered_df[filtered_df['person_uid'] == entity_1].iloc[0]\n",
    "            entity_2_row = filtered_df[filtered_df['person_uid'] == entity_2].iloc[0]\n",
    "\n",
    "            # Compute similarities and differences between entities\n",
    "            features = {\n",
    "                'entity_1_uid': entity_1,\n",
    "                'entity_1_first_name': entity_1_row['first_name'],\n",
    "                'entity_1_last_name': entity_1_row['last_name'],\n",
    "                'entity_1_role': entity_1_row.get('officer_role', ''),\n",
    "                'entity_1_context': entity_1_row.get('officer_context', ''),\n",
    "                'entity_2_uid': entity_2,\n",
    "                'entity_2_first_name': entity_2_row['first_name'],\n",
    "                'entity_2_last_name': entity_2_row['last_name'],\n",
    "                'entity_2_role': entity_2_row.get('officer_role', ''),\n",
    "                'entity_2_context': entity_2_row.get('officer_context', ''),\n",
    "                'first_name_similarity': calculate_string_similarity(entity_1_row['first_name'], entity_2_row['first_name']),\n",
    "                'last_name_similarity': calculate_string_similarity(entity_1_row['last_name'], entity_2_row['last_name']),\n",
    "                'role_similarity': calculate_string_similarity(entity_1_row.get('officer_role', ''), entity_2_row.get('officer_role', '')),\n",
    "                'first_name_length_diff': abs(len(entity_1_row['first_name']) - len(entity_2_row['first_name'])),\n",
    "                'last_name_length_diff': abs(len(entity_1_row['last_name']) - len(entity_2_row['last_name'])),\n",
    "                'context_similarity': calculate_context_similarity([entity_1_row.get('officer_context', '')], [entity_2_row.get('officer_context', '')])[0],\n",
    "            }\n",
    "\n",
    "            comparison_data.append(features)\n",
    "\n",
    "    # Convert comparison data to DataFrame and scale features\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    scaler = MinMaxScaler()\n",
    "    features_to_scale = ['first_name_similarity', 'last_name_similarity', \n",
    "                         'role_similarity', 'first_name_length_diff', \n",
    "                         'last_name_length_diff', 'context_similarity']\n",
    "    comparison_df[features_to_scale] = scaler.fit_transform(comparison_df[features_to_scale])\n",
    "\n",
    "    return comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>officer_context</th>\n",
       "      <th>officer_role</th>\n",
       "      <th>page_number</th>\n",
       "      <th>fn</th>\n",
       "      <th>query</th>\n",
       "      <th>prompt_template_for_hyde</th>\n",
       "      <th>prompt_template_for_model</th>\n",
       "      <th>chunk_size</th>\n",
       "      <th>chunk_overlap</th>\n",
       "      <th>temperature</th>\n",
       "      <th>...</th>\n",
       "      <th>num_of_queries</th>\n",
       "      <th>model</th>\n",
       "      <th>uid</th>\n",
       "      <th>officer_name</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>fc</th>\n",
       "      <th>lc</th>\n",
       "      <th>person_uid</th>\n",
       "      <th>blocking_keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mentioned as one of the officers who verified ...</td>\n",
       "      <td>verifying officer</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>Magistrate     -  Arrest Report.json</td>\n",
       "      <td>Identify each individual in the transcript, by...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo-1603-finetuned-300-labels</td>\n",
       "      <td>612edb73</td>\n",
       "      <td>Dalton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dalton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dalto</td>\n",
       "      <td>6123425393</td>\n",
       "      <td>['dal', 'ton', 'cer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mentioned as providing assistance to officer d...</td>\n",
       "      <td>assisting officer</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>Magistrate     -  Arrest Report.json</td>\n",
       "      <td>Identify each individual in the transcript, by...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo-1603-finetuned-300-labels</td>\n",
       "      <td>612edb73</td>\n",
       "      <td>Victoria Guidry</td>\n",
       "      <td>victoria</td>\n",
       "      <td>guidry</td>\n",
       "      <td>victo</td>\n",
       "      <td>guidr</td>\n",
       "      <td>7006194877</td>\n",
       "      <td>['vic', 'ria', 'gui', 'dry', 'cer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mentioned as one of the officers who arrested ...</td>\n",
       "      <td>arresting officer</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>Magistrate     -  Arrest Report.json</td>\n",
       "      <td>Identify each individual in the transcript, by...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo-1603-finetuned-300-labels</td>\n",
       "      <td>612edb73</td>\n",
       "      <td>Carolyn Dalton</td>\n",
       "      <td>carolyn</td>\n",
       "      <td>dalton</td>\n",
       "      <td>carol</td>\n",
       "      <td>dalto</td>\n",
       "      <td>3613126420</td>\n",
       "      <td>['car', 'lyn', 'dal', 'ton', 'cer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mentioned as one of the officers who booked th...</td>\n",
       "      <td>booking officer</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>Magistrate     -  Arrest Report.json</td>\n",
       "      <td>Identify each individual in the transcript, by...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo-1603-finetuned-300-labels</td>\n",
       "      <td>612edb73</td>\n",
       "      <td>Terry Bean</td>\n",
       "      <td>terry</td>\n",
       "      <td>bean</td>\n",
       "      <td>terry</td>\n",
       "      <td>bean</td>\n",
       "      <td>2271130809</td>\n",
       "      <td>['ter', 'rry', 'bea', 'ean', 'cer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mentioned as one of the officers who verified ...</td>\n",
       "      <td>verifying officer</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>Magistrate     -  Arrest Report.json</td>\n",
       "      <td>Identify each individual in the transcript, by...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo-1603-finetuned-300-labels</td>\n",
       "      <td>612edb73</td>\n",
       "      <td>Dalton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dalton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dalto</td>\n",
       "      <td>3153431315</td>\n",
       "      <td>['dal', 'ton', 'cer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5102</th>\n",
       "      <td>asked if he was the one who arrived to transpo...</td>\n",
       "      <td>investigating officer</td>\n",
       "      <td>[2, 9, 113, 50, 52, 33, 30, 112, 170, 2, 98, 1...</td>\n",
       "      <td>Seward - Suppression Hearing Transcript.json</td>\n",
       "      <td>Identify each individual in the transcript, by...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo-1603-finetuned-300-labels</td>\n",
       "      <td>2a8d20df</td>\n",
       "      <td>Hoyt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hoyt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hoyt</td>\n",
       "      <td>6353150479</td>\n",
       "      <td>['hoy', 'oyt', 'cer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5103</th>\n",
       "      <td>referred to as the one the witness wanted to b...</td>\n",
       "      <td>investigating officer</td>\n",
       "      <td>[2, 9, 113, 50, 52, 33, 30, 112, 170, 2, 98, 1...</td>\n",
       "      <td>Seward - Suppression Hearing Transcript.json</td>\n",
       "      <td>Identify each individual in the transcript, by...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo-1603-finetuned-300-labels</td>\n",
       "      <td>2a8d20df</td>\n",
       "      <td>Dillman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dillman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dillm</td>\n",
       "      <td>8327113279</td>\n",
       "      <td>['dil', 'man', 'cer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104</th>\n",
       "      <td>involved in taking a statement and typed the s...</td>\n",
       "      <td>sergeant</td>\n",
       "      <td>[2, 9, 113, 50, 52, 33, 30, 112, 170, 2, 98, 1...</td>\n",
       "      <td>Seward - Suppression Hearing Transcript.json</td>\n",
       "      <td>Identify each individual in the transcript, by...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo-1603-finetuned-300-labels</td>\n",
       "      <td>2a8d20df</td>\n",
       "      <td>London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>london</td>\n",
       "      <td>NaN</td>\n",
       "      <td>londo</td>\n",
       "      <td>8822828103</td>\n",
       "      <td>['lon', 'don', 'ant']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5105</th>\n",
       "      <td>mentioned as being with other officers during ...</td>\n",
       "      <td>investigating officer</td>\n",
       "      <td>[2, 9, 113, 50, 52, 33, 30, 112, 170, 2, 98, 1...</td>\n",
       "      <td>Seward - Suppression Hearing Transcript.json</td>\n",
       "      <td>Identify each individual in the transcript, by...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo-1603-finetuned-300-labels</td>\n",
       "      <td>2a8d20df</td>\n",
       "      <td>Dantagnan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dantagnan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>danta</td>\n",
       "      <td>5489285986</td>\n",
       "      <td>['dan', 'nan', 'cer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>mentioned as one the witness wanted to call in...</td>\n",
       "      <td>investigating officer</td>\n",
       "      <td>[2, 9, 113, 50, 52, 33, 30, 112, 170, 2, 98, 1...</td>\n",
       "      <td>Seward - Suppression Hearing Transcript.json</td>\n",
       "      <td>Identify each individual in the transcript, by...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo-1603-finetuned-300-labels</td>\n",
       "      <td>2a8d20df</td>\n",
       "      <td>Dillman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dillman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dillm</td>\n",
       "      <td>3655603843</td>\n",
       "      <td>['dil', 'man', 'cer']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5107 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        officer_context  \\\n",
       "0     mentioned as one of the officers who verified ...   \n",
       "1     mentioned as providing assistance to officer d...   \n",
       "2     mentioned as one of the officers who arrested ...   \n",
       "3     mentioned as one of the officers who booked th...   \n",
       "4     mentioned as one of the officers who verified ...   \n",
       "...                                                 ...   \n",
       "5102  asked if he was the one who arrived to transpo...   \n",
       "5103  referred to as the one the witness wanted to b...   \n",
       "5104  involved in taking a statement and typed the s...   \n",
       "5105  mentioned as being with other officers during ...   \n",
       "5106  mentioned as one the witness wanted to call in...   \n",
       "\n",
       "               officer_role  \\\n",
       "0         verifying officer   \n",
       "1         assisting officer   \n",
       "2         arresting officer   \n",
       "3           booking officer   \n",
       "4         verifying officer   \n",
       "...                     ...   \n",
       "5102  investigating officer   \n",
       "5103  investigating officer   \n",
       "5104               sergeant   \n",
       "5105  investigating officer   \n",
       "5106  investigating officer   \n",
       "\n",
       "                                            page_number  \\\n",
       "0                                             [1, 1, 1]   \n",
       "1                                             [1, 1, 1]   \n",
       "2                                             [1, 1, 1]   \n",
       "3                                             [1, 1, 1]   \n",
       "4                                             [1, 1, 1]   \n",
       "...                                                 ...   \n",
       "5102  [2, 9, 113, 50, 52, 33, 30, 112, 170, 2, 98, 1...   \n",
       "5103  [2, 9, 113, 50, 52, 33, 30, 112, 170, 2, 98, 1...   \n",
       "5104  [2, 9, 113, 50, 52, 33, 30, 112, 170, 2, 98, 1...   \n",
       "5105  [2, 9, 113, 50, 52, 33, 30, 112, 170, 2, 98, 1...   \n",
       "5106  [2, 9, 113, 50, 52, 33, 30, 112, 170, 2, 98, 1...   \n",
       "\n",
       "                                                fn  \\\n",
       "0             Magistrate     -  Arrest Report.json   \n",
       "1             Magistrate     -  Arrest Report.json   \n",
       "2             Magistrate     -  Arrest Report.json   \n",
       "3             Magistrate     -  Arrest Report.json   \n",
       "4             Magistrate     -  Arrest Report.json   \n",
       "...                                            ...   \n",
       "5102  Seward - Suppression Hearing Transcript.json   \n",
       "5103  Seward - Suppression Hearing Transcript.json   \n",
       "5104  Seward - Suppression Hearing Transcript.json   \n",
       "5105  Seward - Suppression Hearing Transcript.json   \n",
       "5106  Seward - Suppression Hearing Transcript.json   \n",
       "\n",
       "                                                  query  \\\n",
       "0     Identify each individual in the transcript, by...   \n",
       "1     Identify each individual in the transcript, by...   \n",
       "2     Identify each individual in the transcript, by...   \n",
       "3     Identify each individual in the transcript, by...   \n",
       "4     Identify each individual in the transcript, by...   \n",
       "...                                                 ...   \n",
       "5102  Identify each individual in the transcript, by...   \n",
       "5103  Identify each individual in the transcript, by...   \n",
       "5104  Identify each individual in the transcript, by...   \n",
       "5105  Identify each individual in the transcript, by...   \n",
       "5106  Identify each individual in the transcript, by...   \n",
       "\n",
       "     prompt_template_for_hyde prompt_template_for_model  chunk_size  \\\n",
       "0                         NaN                       NaN         500   \n",
       "1                         NaN                       NaN         500   \n",
       "2                         NaN                       NaN         500   \n",
       "3                         NaN                       NaN         500   \n",
       "4                         NaN                       NaN         500   \n",
       "...                       ...                       ...         ...   \n",
       "5102                      NaN                       NaN         500   \n",
       "5103                      NaN                       NaN         500   \n",
       "5104                      NaN                       NaN         500   \n",
       "5105                      NaN                       NaN         500   \n",
       "5106                      NaN                       NaN         500   \n",
       "\n",
       "      chunk_overlap  temperature  ...  num_of_queries  \\\n",
       "0               250            1  ...               1   \n",
       "1               250            1  ...               1   \n",
       "2               250            1  ...               1   \n",
       "3               250            1  ...               1   \n",
       "4               250            1  ...               1   \n",
       "...             ...          ...  ...             ...   \n",
       "5102            250            1  ...               1   \n",
       "5103            250            1  ...               1   \n",
       "5104            250            1  ...               1   \n",
       "5105            250            1  ...               1   \n",
       "5106            250            1  ...               1   \n",
       "\n",
       "                                        model       uid     officer_name  \\\n",
       "0     gpt-3.5-turbo-1603-finetuned-300-labels  612edb73           Dalton   \n",
       "1     gpt-3.5-turbo-1603-finetuned-300-labels  612edb73  Victoria Guidry   \n",
       "2     gpt-3.5-turbo-1603-finetuned-300-labels  612edb73   Carolyn Dalton   \n",
       "3     gpt-3.5-turbo-1603-finetuned-300-labels  612edb73       Terry Bean   \n",
       "4     gpt-3.5-turbo-1603-finetuned-300-labels  612edb73           Dalton   \n",
       "...                                       ...       ...              ...   \n",
       "5102  gpt-3.5-turbo-1603-finetuned-300-labels  2a8d20df             Hoyt   \n",
       "5103  gpt-3.5-turbo-1603-finetuned-300-labels  2a8d20df          Dillman   \n",
       "5104  gpt-3.5-turbo-1603-finetuned-300-labels  2a8d20df           London   \n",
       "5105  gpt-3.5-turbo-1603-finetuned-300-labels  2a8d20df        Dantagnan   \n",
       "5106  gpt-3.5-turbo-1603-finetuned-300-labels  2a8d20df          Dillman   \n",
       "\n",
       "     first_name  last_name     fc     lc  person_uid  \\\n",
       "0           NaN     dalton    NaN  dalto  6123425393   \n",
       "1      victoria     guidry  victo  guidr  7006194877   \n",
       "2       carolyn     dalton  carol  dalto  3613126420   \n",
       "3         terry       bean  terry   bean  2271130809   \n",
       "4           NaN     dalton    NaN  dalto  3153431315   \n",
       "...         ...        ...    ...    ...         ...   \n",
       "5102        NaN       hoyt    NaN   hoyt  6353150479   \n",
       "5103        NaN    dillman    NaN  dillm  8327113279   \n",
       "5104        NaN     london    NaN  londo  8822828103   \n",
       "5105        NaN  dantagnan    NaN  danta  5489285986   \n",
       "5106        NaN    dillman    NaN  dillm  3655603843   \n",
       "\n",
       "                            blocking_keys  \n",
       "0                   ['dal', 'ton', 'cer']  \n",
       "1     ['vic', 'ria', 'gui', 'dry', 'cer']  \n",
       "2     ['car', 'lyn', 'dal', 'ton', 'cer']  \n",
       "3     ['ter', 'rry', 'bea', 'ean', 'cer']  \n",
       "4                   ['dal', 'ton', 'cer']  \n",
       "...                                   ...  \n",
       "5102                ['hoy', 'oyt', 'cer']  \n",
       "5103                ['dil', 'man', 'cer']  \n",
       "5104                ['lon', 'don', 'ant']  \n",
       "5105                ['dan', 'nan', 'cer']  \n",
       "5106                ['dil', 'man', 'cer']  \n",
       "\n",
       "[5107 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_csv()\n",
    "\n",
    "df\n",
    "\n",
    "# df = df.iloc[:10]\n",
    "\n",
    "# df = df.pipe(generate_pairwise_comparisons)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"../data/output/output-pairwise-scales.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
