{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import nltk\n",
    "from itertools import combinations\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import jellyfish\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv():\n",
    "    df = pd.read_csv(\"../../ts-feature-engineering/data/output/features.csv\")\n",
    "\n",
    "    df['normalized_label'] = (df['label']\n",
    "                              .str.lower()\n",
    "                              .str.strip()\n",
    "                              .str.replace(r\"(easy match|hard match)\", \"1\", regex=True)\n",
    "                              .str.replace(r\"(easy non-match|hard non-match)\", \"0\", regex=True)\n",
    "    )\n",
    "\n",
    "    df.loc[:, \"label_numeric\"] = df[\"normalized_label\"].astype(int)\n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows_with_multiple_officers(df):\n",
    "    df = (\n",
    "        df.drop(\"split_indv\", axis=1)\n",
    "        .join(\n",
    "            df[\"split_indv\"]\n",
    "            .str.split(\"@\", expand=True)\n",
    "            .stack()\n",
    "            .reset_index(level=1, drop=True)\n",
    "            .rename(\"split_indv\"),\n",
    "            how=\"outer\",\n",
    "        )\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno 8] nodename nor\n",
      "[nltk_data]     servname provided, or not known>\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')  \n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "def tokenize_and_stem(context):\n",
    "    tokens = word_tokenize(context)  \n",
    "    stemmed_tokens = stem_tokens(tokens) \n",
    "    return stemmed_tokens\n",
    "\n",
    "def calculate_string_similarity(s1, s2):\n",
    "    return jellyfish.jaro_winkler_similarity(s1, s2)\n",
    "\n",
    "def calculate_context_similarity(contexts1, contexts2):\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "    embeddings1 = model.encode(contexts1, convert_to_tensor=True)\n",
    "    embeddings2 = model.encode(contexts2, convert_to_tensor=True)\n",
    "    \n",
    "    embeddings1_np = embeddings1.cpu().numpy()\n",
    "    embeddings2_np = embeddings2.cpu().numpy()\n",
    "    \n",
    "    cosine_similarities = np.diag(cosine_similarity(embeddings1_np, embeddings2_np)).tolist()\n",
    "    \n",
    "    return cosine_similarities\n",
    "\n",
    "def generate_pairwise_comparisons(df):\n",
    "    df = df.fillna(\"\")\n",
    "    comparison_data = []\n",
    "\n",
    "    # Flatten the list of all blocking keys to find unique keys across the dataset\n",
    "    all_keys = set([key for sublist in df['blocking_keys'] for key in sublist])\n",
    "    \n",
    "    for key in all_keys:\n",
    "        # Find all records that have this blocking key\n",
    "        filtered_df = df[df['blocking_keys'].apply(lambda x: key in x)]\n",
    "        unique_entities = filtered_df['person_uid'].unique()\n",
    "\n",
    "        # Generate all combinations of unique entities within this filtered group\n",
    "        for entity_1, entity_2 in combinations(unique_entities, 2):\n",
    "            entity_1_row = filtered_df[filtered_df['person_uid'] == entity_1].iloc[0]\n",
    "            entity_2_row = filtered_df[filtered_df['person_uid'] == entity_2].iloc[0]\n",
    "\n",
    "            # Compute similarities and differences between entities\n",
    "            features = {\n",
    "                'entity_1_uid': entity_1,\n",
    "                'entity_1_first_name': entity_1_row['first_name'],\n",
    "                'entity_1_last_name': entity_1_row['last_name'],\n",
    "                'entity_1_role': entity_1_row.get('officer_role', ''),\n",
    "                'entity_1_context': entity_1_row.get('officer_context', ''),\n",
    "                'entity_2_uid': entity_2,\n",
    "                'entity_2_first_name': entity_2_row['first_name'],\n",
    "                'entity_2_last_name': entity_2_row['last_name'],\n",
    "                'entity_2_role': entity_2_row.get('officer_role', ''),\n",
    "                'entity_2_context': entity_2_row.get('officer_context', ''),\n",
    "                'first_name_similarity': calculate_string_similarity(entity_1_row['first_name'], entity_2_row['first_name']),\n",
    "                'last_name_similarity': calculate_string_similarity(entity_1_row['last_name'], entity_2_row['last_name']),\n",
    "                'role_similarity': calculate_string_similarity(entity_1_row.get('officer_role', ''), entity_2_row.get('officer_role', '')),\n",
    "                'first_name_length_diff': abs(len(entity_1_row['first_name']) - len(entity_2_row['first_name'])),\n",
    "                'last_name_length_diff': abs(len(entity_1_row['last_name']) - len(entity_2_row['last_name'])),\n",
    "                'context_similarity': calculate_context_similarity([entity_1_row.get('officer_context', '')], [entity_2_row.get('officer_context', '')])[0],\n",
    "            }\n",
    "\n",
    "            comparison_data.append(features)\n",
    "\n",
    "    # Convert comparison data to DataFrame and scale features\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    scaler = MinMaxScaler()\n",
    "    features_to_scale = ['first_name_similarity', 'last_name_similarity', \n",
    "                         'role_similarity', 'first_name_length_diff', \n",
    "                         'last_name_length_diff', 'context_similarity']\n",
    "    comparison_df[features_to_scale] = scaler.fit_transform(comparison_df[features_to_scale])\n",
    "\n",
    "    return comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_1_first_name</th>\n",
       "      <th>entity_1_last_name</th>\n",
       "      <th>entity_1_rank</th>\n",
       "      <th>entity_1_context</th>\n",
       "      <th>entity_2_first_name</th>\n",
       "      <th>entity_2_last_name</th>\n",
       "      <th>entity_2_rank</th>\n",
       "      <th>entity_2_context</th>\n",
       "      <th>label</th>\n",
       "      <th>first_name_similarity</th>\n",
       "      <th>...</th>\n",
       "      <th>entity_2_uid</th>\n",
       "      <th>normalized_label</th>\n",
       "      <th>label_numeric</th>\n",
       "      <th>indv_1</th>\n",
       "      <th>indv_2</th>\n",
       "      <th>split_indv</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>officer_role</th>\n",
       "      <th>officer_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>rodrigue</td>\n",
       "      <td>investigating detective</td>\n",
       "      <td>Directly involved in the investigation of the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rodriguez</td>\n",
       "      <td>detective</td>\n",
       "      <td>Mentioned as someone the speaker went to the c...</td>\n",
       "      <td>Hard non-match</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>dd4c983730a24553301ee69e1efb32e00fd03839ab1673...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dewilliam</td>\n",
       "      <td>trepagnier #1504</td>\n",
       "      <td>detective</td>\n",
       "      <td>Mentioned in context with the search and inter...</td>\n",
       "      <td>dewilliam</td>\n",
       "      <td>trepagnier</td>\n",
       "      <td>detective</td>\n",
       "      <td>Mentioned in a context related to the crime la...</td>\n",
       "      <td>Easy match</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>48313dc154307cb1cc114afc7b7084b2ecf73cbd4230c0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>dewilliam*trepagnier #1504*detective*Mentioned...</td>\n",
       "      <td>dewilliam*trepagnier*detective*Mentioned in a ...</td>\n",
       "      <td>dewilliam*trepagnier #1504*detective*Mentioned...</td>\n",
       "      <td>dewillia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dewilliam</td>\n",
       "      <td>trepagnier #1504</td>\n",
       "      <td>detective</td>\n",
       "      <td>Mentioned in context with the search and inter...</td>\n",
       "      <td>dewilliam</td>\n",
       "      <td>trepagnier</td>\n",
       "      <td>detective</td>\n",
       "      <td>Mentioned in a context related to the crime la...</td>\n",
       "      <td>Easy match</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>48313dc154307cb1cc114afc7b7084b2ecf73cbd4230c0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>dewilliam*trepagnier #1504*detective*Mentioned...</td>\n",
       "      <td>dewilliam*trepagnier*detective*Mentioned in a ...</td>\n",
       "      <td>dewilliam*trepagnier*detective*Mentioned in a ...</td>\n",
       "      <td>dewillia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dewilliam</td>\n",
       "      <td>trepagnier #1504</td>\n",
       "      <td>detective</td>\n",
       "      <td>Mentioned in context with the search and inter...</td>\n",
       "      <td>dewilliam</td>\n",
       "      <td>trepagnier #1504</td>\n",
       "      <td>detective</td>\n",
       "      <td>Mentioned in relation to conducting interviews...</td>\n",
       "      <td>Easy match</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>fd9e8ef4a53913e12dc042aad6006403ecd4bad2a2d826...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>dewilliam*trepagnier #1504*detective*Mentioned...</td>\n",
       "      <td>dewilliam*trepagnier #1504*detective*Mentioned...</td>\n",
       "      <td>dewilliam*trepagnier #1504*detective*Mentioned...</td>\n",
       "      <td>dewillia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dewilliam</td>\n",
       "      <td>trepagnier #1504</td>\n",
       "      <td>detective</td>\n",
       "      <td>Mentioned in context with the search and inter...</td>\n",
       "      <td>dewilliam</td>\n",
       "      <td>trepagnier #1504</td>\n",
       "      <td>detective</td>\n",
       "      <td>Mentioned in relation to conducting interviews...</td>\n",
       "      <td>Easy match</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>fd9e8ef4a53913e12dc042aad6006403ecd4bad2a2d826...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>dewilliam*trepagnier #1504*detective*Mentioned...</td>\n",
       "      <td>dewilliam*trepagnier #1504*detective*Mentioned...</td>\n",
       "      <td>dewilliam*trepagnier #1504*detective*Mentioned...</td>\n",
       "      <td>dewillia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>debbie</td>\n",
       "      <td>coffee</td>\n",
       "      <td>lead detective</td>\n",
       "      <td>Mentioned as the lead police officer in a case...</td>\n",
       "      <td>louis</td>\n",
       "      <td>berard</td>\n",
       "      <td>detective</td>\n",
       "      <td>Testified as a Detective and Police Officer in...</td>\n",
       "      <td>easy non-match</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>...</td>\n",
       "      <td>aa667086e0c5d4e2d5ae428eef9e55d33646832c7680f2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>debbie*coffee*lead detective*Mentioned as the ...</td>\n",
       "      <td>louis*berard*detective*Testified as a Detectiv...</td>\n",
       "      <td>louis*berard*detective*Testified as a Detectiv...</td>\n",
       "      <td>loui</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>debbie</td>\n",
       "      <td>coffee</td>\n",
       "      <td>rape detective</td>\n",
       "      <td>Mentioned as working in the Rape Section.</td>\n",
       "      <td>louis</td>\n",
       "      <td>berard</td>\n",
       "      <td>homicide division detective</td>\n",
       "      <td>Mentioned as a Detective from the New Orleans ...</td>\n",
       "      <td>easy non-match</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>...</td>\n",
       "      <td>a56ec822462dda139e8642d3dfd1f70bdd5423073c254a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>debbie*coffee*rape detective*Mentioned as work...</td>\n",
       "      <td>louis*berard*homicide division detective*Menti...</td>\n",
       "      <td>debbie*coffee*rape detective*Mentioned as work...</td>\n",
       "      <td>debbi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>debbie</td>\n",
       "      <td>coffee</td>\n",
       "      <td>rape detective</td>\n",
       "      <td>Mentioned as working in the Rape Section.</td>\n",
       "      <td>louis</td>\n",
       "      <td>berard</td>\n",
       "      <td>homicide division detective</td>\n",
       "      <td>Mentioned as a Detective from the New Orleans ...</td>\n",
       "      <td>easy non-match</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>...</td>\n",
       "      <td>a56ec822462dda139e8642d3dfd1f70bdd5423073c254a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>debbie*coffee*rape detective*Mentioned as work...</td>\n",
       "      <td>louis*berard*homicide division detective*Menti...</td>\n",
       "      <td>louis*berard*homicide division detective*Menti...</td>\n",
       "      <td>loui</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>debbie</td>\n",
       "      <td>coffee</td>\n",
       "      <td>lead detective</td>\n",
       "      <td>Mentioned as collaborating with Detective Al S...</td>\n",
       "      <td>louis</td>\n",
       "      <td>berard</td>\n",
       "      <td>detective (homicide division)</td>\n",
       "      <td>Testified as a Police Officer from the Homicid...</td>\n",
       "      <td>easy non-match</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>...</td>\n",
       "      <td>6590f2642b350b42e0acb0aa4348ddd6f6a8cc52987707...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>debbie*coffee*lead detective*Mentioned as coll...</td>\n",
       "      <td>louis*berard*detective (homicide division)*Tes...</td>\n",
       "      <td>debbie*coffee*lead detective*Mentioned as coll...</td>\n",
       "      <td>debbi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>debbie</td>\n",
       "      <td>coffee</td>\n",
       "      <td>lead detective</td>\n",
       "      <td>Mentioned as collaborating with Detective Al S...</td>\n",
       "      <td>louis</td>\n",
       "      <td>berard</td>\n",
       "      <td>detective (homicide division)</td>\n",
       "      <td>Testified as a Police Officer from the Homicid...</td>\n",
       "      <td>easy non-match</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>...</td>\n",
       "      <td>6590f2642b350b42e0acb0aa4348ddd6f6a8cc52987707...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>debbie*coffee*lead detective*Mentioned as coll...</td>\n",
       "      <td>louis*berard*detective (homicide division)*Tes...</td>\n",
       "      <td>louis*berard*detective (homicide division)*Tes...</td>\n",
       "      <td>loui</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2026 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     entity_1_first_name entity_1_last_name            entity_1_rank  \\\n",
       "0                    NaN           rodrigue  investigating detective   \n",
       "1              dewilliam   trepagnier #1504                detective   \n",
       "2              dewilliam   trepagnier #1504                detective   \n",
       "3              dewilliam   trepagnier #1504                detective   \n",
       "4              dewilliam   trepagnier #1504                detective   \n",
       "...                  ...                ...                      ...   \n",
       "2021              debbie             coffee           lead detective   \n",
       "2022              debbie             coffee           rape detective   \n",
       "2023              debbie             coffee           rape detective   \n",
       "2024              debbie             coffee           lead detective   \n",
       "2025              debbie             coffee           lead detective   \n",
       "\n",
       "                                       entity_1_context entity_2_first_name  \\\n",
       "0     Directly involved in the investigation of the ...                 NaN   \n",
       "1     Mentioned in context with the search and inter...           dewilliam   \n",
       "2     Mentioned in context with the search and inter...           dewilliam   \n",
       "3     Mentioned in context with the search and inter...           dewilliam   \n",
       "4     Mentioned in context with the search and inter...           dewilliam   \n",
       "...                                                 ...                 ...   \n",
       "2021  Mentioned as the lead police officer in a case...               louis   \n",
       "2022          Mentioned as working in the Rape Section.               louis   \n",
       "2023          Mentioned as working in the Rape Section.               louis   \n",
       "2024  Mentioned as collaborating with Detective Al S...               louis   \n",
       "2025  Mentioned as collaborating with Detective Al S...               louis   \n",
       "\n",
       "     entity_2_last_name                  entity_2_rank  \\\n",
       "0             rodriguez                      detective   \n",
       "1            trepagnier                      detective   \n",
       "2            trepagnier                      detective   \n",
       "3      trepagnier #1504                      detective   \n",
       "4      trepagnier #1504                      detective   \n",
       "...                 ...                            ...   \n",
       "2021             berard                      detective   \n",
       "2022             berard    homicide division detective   \n",
       "2023             berard    homicide division detective   \n",
       "2024             berard  detective (homicide division)   \n",
       "2025             berard  detective (homicide division)   \n",
       "\n",
       "                                       entity_2_context           label  \\\n",
       "0     Mentioned as someone the speaker went to the c...  Hard non-match   \n",
       "1     Mentioned in a context related to the crime la...      Easy match   \n",
       "2     Mentioned in a context related to the crime la...      Easy match   \n",
       "3     Mentioned in relation to conducting interviews...      Easy match   \n",
       "4     Mentioned in relation to conducting interviews...      Easy match   \n",
       "...                                                 ...             ...   \n",
       "2021  Testified as a Detective and Police Officer in...  easy non-match   \n",
       "2022  Mentioned as a Detective from the New Orleans ...  easy non-match   \n",
       "2023  Mentioned as a Detective from the New Orleans ...  easy non-match   \n",
       "2024  Testified as a Police Officer from the Homicid...  easy non-match   \n",
       "2025  Testified as a Police Officer from the Homicid...  easy non-match   \n",
       "\n",
       "      first_name_similarity  ...  \\\n",
       "0                  0.000000  ...   \n",
       "1                  1.000000  ...   \n",
       "2                  1.000000  ...   \n",
       "3                  1.000000  ...   \n",
       "4                  1.000000  ...   \n",
       "...                     ...  ...   \n",
       "2021               0.455556  ...   \n",
       "2022               0.455556  ...   \n",
       "2023               0.455556  ...   \n",
       "2024               0.455556  ...   \n",
       "2025               0.455556  ...   \n",
       "\n",
       "                                           entity_2_uid  normalized_label  \\\n",
       "0     dd4c983730a24553301ee69e1efb32e00fd03839ab1673...                 0   \n",
       "1     48313dc154307cb1cc114afc7b7084b2ecf73cbd4230c0...                 1   \n",
       "2     48313dc154307cb1cc114afc7b7084b2ecf73cbd4230c0...                 1   \n",
       "3     fd9e8ef4a53913e12dc042aad6006403ecd4bad2a2d826...                 1   \n",
       "4     fd9e8ef4a53913e12dc042aad6006403ecd4bad2a2d826...                 1   \n",
       "...                                                 ...               ...   \n",
       "2021  aa667086e0c5d4e2d5ae428eef9e55d33646832c7680f2...                 0   \n",
       "2022  a56ec822462dda139e8642d3dfd1f70bdd5423073c254a...                 0   \n",
       "2023  a56ec822462dda139e8642d3dfd1f70bdd5423073c254a...                 0   \n",
       "2024  6590f2642b350b42e0acb0aa4348ddd6f6a8cc52987707...                 0   \n",
       "2025  6590f2642b350b42e0acb0aa4348ddd6f6a8cc52987707...                 0   \n",
       "\n",
       "      label_numeric                                             indv_1  \\\n",
       "0                 0                                                NaN   \n",
       "1                 1  dewilliam*trepagnier #1504*detective*Mentioned...   \n",
       "2                 1  dewilliam*trepagnier #1504*detective*Mentioned...   \n",
       "3                 1  dewilliam*trepagnier #1504*detective*Mentioned...   \n",
       "4                 1  dewilliam*trepagnier #1504*detective*Mentioned...   \n",
       "...             ...                                                ...   \n",
       "2021              0  debbie*coffee*lead detective*Mentioned as the ...   \n",
       "2022              0  debbie*coffee*rape detective*Mentioned as work...   \n",
       "2023              0  debbie*coffee*rape detective*Mentioned as work...   \n",
       "2024              0  debbie*coffee*lead detective*Mentioned as coll...   \n",
       "2025              0  debbie*coffee*lead detective*Mentioned as coll...   \n",
       "\n",
       "                                                 indv_2  \\\n",
       "0                                                   NaN   \n",
       "1     dewilliam*trepagnier*detective*Mentioned in a ...   \n",
       "2     dewilliam*trepagnier*detective*Mentioned in a ...   \n",
       "3     dewilliam*trepagnier #1504*detective*Mentioned...   \n",
       "4     dewilliam*trepagnier #1504*detective*Mentioned...   \n",
       "...                                                 ...   \n",
       "2021  louis*berard*detective*Testified as a Detectiv...   \n",
       "2022  louis*berard*homicide division detective*Menti...   \n",
       "2023  louis*berard*homicide division detective*Menti...   \n",
       "2024  louis*berard*detective (homicide division)*Tes...   \n",
       "2025  louis*berard*detective (homicide division)*Tes...   \n",
       "\n",
       "                                             split_indv first_name last_name  \\\n",
       "0                                                   NaN        NaN       NaN   \n",
       "1     dewilliam*trepagnier #1504*detective*Mentioned...   dewillia       NaN   \n",
       "2     dewilliam*trepagnier*detective*Mentioned in a ...   dewillia       NaN   \n",
       "3     dewilliam*trepagnier #1504*detective*Mentioned...   dewillia       NaN   \n",
       "4     dewilliam*trepagnier #1504*detective*Mentioned...   dewillia       NaN   \n",
       "...                                                 ...        ...       ...   \n",
       "2021  louis*berard*detective*Testified as a Detectiv...       loui       NaN   \n",
       "2022  debbie*coffee*rape detective*Mentioned as work...      debbi       NaN   \n",
       "2023  louis*berard*homicide division detective*Menti...       loui       NaN   \n",
       "2024  debbie*coffee*lead detective*Mentioned as coll...      debbi       NaN   \n",
       "2025  louis*berard*detective (homicide division)*Tes...       loui       NaN   \n",
       "\n",
       "      officer_role officer_context  \n",
       "0              NaN             NaN  \n",
       "1              NaN               m  \n",
       "2              NaN               m  \n",
       "3              NaN               m  \n",
       "4              NaN               m  \n",
       "...            ...             ...  \n",
       "2021           NaN               s  \n",
       "2022           NaN               e  \n",
       "2023           NaN               s  \n",
       "2024           NaN               e  \n",
       "2025           NaN               s  \n",
       "\n",
       "[2026 rows x 26 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_csv()\n",
    "\n",
    "df\n",
    "\n",
    "\n",
    "df.loc[:, \"indv_1\"] = df.entity_1_first_name.str.cat(df.entity_1_last_name, sep=\"*\").str.cat(df.entity_1_rank, sep=\"*\").str.cat(df.entity_1_context, sep=\"*\")\n",
    "df.loc[:, \"indv_2\"] = df.entity_2_first_name.str.cat(df.entity_2_last_name, sep=\"*\").str.cat(df.entity_2_rank, sep=\"*\").str.cat(df.entity_2_context, sep=\"*\")\n",
    "\n",
    "df.loc[:, \"split_indv\"] = df.indv_1.str.cat(df.indv_2, sep=\"@\")\n",
    "\n",
    "df = df.pipe(split_rows_with_multiple_officers)\n",
    "\n",
    "info = df.split_indv.str.extract(r\"(.+)*(\\w+)*(\\w+)*(\\w+)\")\n",
    "\n",
    "df.loc[:, \"first_name\"] = info[0]\n",
    "\n",
    "df.loc[:, \"last_name\"] = info[1]\n",
    "\n",
    "df.loc[:, \"officer_role\"] = info[2]\n",
    "\n",
    "df.loc[:, \"officer_context\"] = info[3]\n",
    "\n",
    "\n",
    "\n",
    "df\n",
    "\n",
    "\n",
    "# df.loc[:, \"person_1\", \"person_2\"] = df.split_indv.str.split(\"@\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df\n",
    "\n",
    "# df = df.iloc[:10]\n",
    "\n",
    "# df = df.pipe(generate_pairwise_comparisons)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"../data/output/output-pairwise-scales.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
